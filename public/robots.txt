# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# This file is used to tell search engine crawlers which pages or files
# the crawler can or can't request from your site.

# Allow all user-agents to crawl the entire site.
User-agent: *
Allow: /

# Specify the location of the sitemap.
Sitemap: https://www.apartmentcompliance.com/sitemap.xml 